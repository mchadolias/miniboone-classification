# MiniBooNE Particle Classification

![Tests](https://github.com/mchadolias/miniboone-classification/actions/workflows/test.yml/badge.svg)

A fully modular, reproducible machine-learning pipeline for distinguishing **electron neutrinos (signal)** from **muon neutrinos (background)** in the MiniBooNE particle-physics dataset.

This project provides:

- ğŸš€ Automated **download**, **loading**, **cleaning**, **processing**, and **splitting** of MiniBooNE PID data
- ğŸ“Š Publication-quality **physics-aware visualizations**
- ğŸ§  Machine-learning support and extensibility (XGBoost, future deep models)
- ğŸ§ª A comprehensive, structured **test suite** (unit + integration + performance)
- ğŸ›  Modern **project architecture** following PyPA and scientific computing best practices
- ğŸ” A research workflow with **data lineage**, reproducibility, and structured configuration

## ğŸš€ Key Features

### ğŸ§¬ Pipeline

- Unified data ingestion (Kaggle or local files)
- Robust cleaning of NaNs, MiniBooNE sentinel values, and duplicates
- Physics-aware preprocessing and feature transformations
- Flexible outputs: **NumPy arrays** or **Pandas DataFrames**

### ğŸ“Š Visualization

- Signalâ€“background separation plots (KDE, histograms)
- Correlation analysis and feature summary plots
- PCA, t-SNE, and other embedding visualizations
- Publication-ready scientific styling (LaTeX optional)

### ğŸ“ Statistical Toolkit

- Effect size computation (Cohenâ€™s *d*, rank-biserial)
- Hypothesis testing and multi-comparison correction
- Feature separability scoring and ranking

### ğŸ§ª Testing Framework

- Mocked external dependencies (Kaggle API, I/O)
- Comprehensive unit tests for loader, cleaner, processor, and plotters
- Statistical validation tests
- Integration, smoke, and performance tests

### ğŸ— Engineering & Workflow

- CI/CD via GitHub Actions
- YAML-driven logging (colored console, JSON optional)
- Standardized Makefile automation
- Modular and research-oriented `src/` architecture

---

## ğŸ“ Project Structure

```markdown
miniboone-classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/                         # Raw third-party datasets (e.g., MiniBooNE PID CSV)
â”‚   â””â”€â”€ processed/                        # Cleaned + transformed datasets ready for modeling
â”œâ”€â”€ notebooks/                            # Exploratory notebooks (numbered for execution order)
â”‚   â””â”€â”€ 01_data_exploration.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/                           # Centralized configuration & presets
â”‚   â”‚   â”œâ”€â”€ config.py                     # Pydantic-based config management
â”‚   â”‚   â”œâ”€â”€ logging.yaml                  # Logging configuration
â”‚   â”‚   â””â”€â”€ presets.py                    # Plotting & model presets
â”‚   â”œâ”€â”€ data/                       
â”‚   â”‚   â”œâ”€â”€ data_loader.py                # Kaggle downloader & local loader
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py               # Missing data, outlier logic, physics adjustments
â”‚   â”‚   â”œâ”€â”€ data_processor.py             # Feature builders, scaling pipeline, splits
â”‚   â”‚   â””â”€â”€ data_handler.py               # High-level pipeline wrapper (load â†’ clean â†’ process)
â”‚   â”‚
â”‚   â”œâ”€â”€ plotter/                    
â”‚   â”‚   â”œâ”€â”€ base_plotter.py               # Scientific plotting setup + LaTeX styles
â”‚   â”‚   â”œâ”€â”€ neutrino_plotter.py           # Physics-aware plots (signal vs background, correlations)
â”‚   â”‚   â””â”€â”€ dimensionality_plotter.py     # PCA, t-SNE, embeddings
â”‚   â”œâ”€â”€ stats/
â”‚   â”‚   â””â”€â”€ statistical_analysis.py       # Statistical tests, effect sizes, corrections
â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â””â”€â”€ plot_style.py                 # Global Matplotlib/SciPlot styling
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py                     # Global logger loader (YAML-driven)
â”‚       â””â”€â”€ paths.py                      # Project-root resolution utilities
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py                       # Shared fixtures for all tests
â”‚   â”œâ”€â”€ integration/                      # Combined integration tests
â”‚   â”œâ”€â”€ unit/                             # Unit Tests for individual module parts
â”‚   â”œâ”€â”€ output/                           # Temporary files generated during testing
â”‚   â”œâ”€â”€ reports/                          # Coverage & diagnostics (HTML reports)
â”‚   â””â”€â”€ test_smokes.py                    # Quick, fast-running smoke tests
â”œâ”€â”€ logs/                                 # Log files (if enabled in logging.yaml)
â”œâ”€â”€ mlruns/                               # MLflow folder housing model registry and summaries
â”œâ”€â”€ tmp/                                  # Temporary scripts & scratch files
â”œâ”€â”€ Makefile                              # Build, test, clean, format commands
â”œâ”€â”€ pyproject.toml                        # Dependency & build configuration
â”œâ”€â”€ setup.cfg                             # Linting/formatting settings
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md                      
```

## ğŸ›  Installation

```bash
git clone https://github.com/mchadolias/miniboone-classification
cd miniboone-classification
```

### Kaggle setup

```bash
mkdir -p ~/.config/kaggle
cp kaggle.json ~/.config/kaggle/
chmod 600 ~/.config/kaggle/kaggle.json
```

### Install dependencies

```bash
uv sync    # or: pip install -r requirements.txt
```

---

## ğŸ¯ Usage Example

### Load â†’ Clean â†’ Process the dataset

```python
from src.data.data_handler import MiniBooNEDataHandler

handler = MiniBooNEDataHandler()

# Run full pipeline
df_clean, splits, pipeline = handler.run()

X_train, y_train = splits["train"]
```

### Generate physics plots

```python
from src.plotter.neutrino_plotter import NeutrinoPlotter

plotter = NeutrinoPlotter()
plotter.plot_feature_separation(df_clean, features=["feature_1", "feature_5"])
```

### Dimensionality reduction

```python
from src.plotter.dimensionality_reduction_plotter import DimensionalityReductionPlotter

dr = DimensionalityReductionPlotter()
fig = dr.plot_tsne_embedding(df_clean)
```

---

## ğŸ§ª Testing Command Sheet

```bash
make test            # full test suite
make test-dev        # fast local tests
make test-cov        # coverage
make lint            # static analysis
make format          # format with black/isort
```

---

## ğŸ“Š About the Data

The MiniBooNE detector dataset contains:

- 50 reconstructed PMT & hit-structure features
- ~93k muon-neutrino background events
- ~36k electron-neutrino signal events

This project handles the common MiniBooNE preprocessing steps:

- Replace MiniBooNEâ€™s sentinel missing value `-999`
- Column-wise median imputation
- Feature scaling and (optional) transforms
- Train/val/test splitting with reproducible seeds

---

## ğŸ“š Roadmap

- [x] Full data pipeline orchestration
- [x] Physics-aware plotting module
- [x] YAML logging system
- [x] Advanced statistics module
- [ ] ML training pipeline (XGBoost, tabular NN)
- [ ] Feature importance + SHAP
- [ ] MLflow experiment tracking
- [ ] Hyperparameter search
- [ ] Add real detector-inspired feature engineering

---

## ğŸ“ License

MIT â€” see [LICENSE](LICENSE).

## ğŸ“… Last Updated

*Date: 06/12/2025*

## ğŸ‘¤ Author

- Michalis Chadolias  
- Email: mchadolias[@]gmail.com  
- GitHub: [https://github.com/mchadolias](https://github.com/mchadolias)
